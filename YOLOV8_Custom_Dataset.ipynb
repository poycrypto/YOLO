{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "from roboflow import Roboflow\n",
    "from ultralytics import YOLO\n",
    "from PIL import Image\n",
    "import math\n",
    "import time\n",
    "import snap7\n",
    "import openvino as ov"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import openvino as ov"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "core = ov.Core()\n",
    "core.get_available_devices()\n",
    "# core.read_model(\"Intel(R) Iris(R) Xe Graphics\")\n",
    "# comp_model = core.compile_model(\"handle_cover_m2_openvino_model/handle_cover_m2.xml\", \"GPU\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cpu_device_name = core.get_property(\"GPU\", \"FULL_DEVICE_NAME\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cpu_device_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TRAINING CUSTOM DATASET WITH PRE- ANNOTATED IMAGES FROM ROBOFLOW"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from roboflow import Roboflow\n",
    "from ultralytics import YOLO\n",
    "\n",
    "rf = Roboflow(api_key=\"Om8Ts8Ct9CobGkaiQI86\")\n",
    "project = rf.workspace(\"roboflow-jvuqo\").project(\"football-players-detection-3zvbc\")\n",
    "version = project.version(2)\n",
    "dataset = version.download(\"yolov8\")\n",
    "\n",
    "model = YOLO(\"yolov8m.pt\")\n",
    "model.train(data = \"data.yaml\", epochs = 2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# IMAGE OBJECT DETECTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = YOLO(\"handle_cover_nano_400.pt\")\n",
    "results = model.predict(source = \"9002592753X1505D_CE_M2XX101_2_20240604125611_NOK.png\", imgsz=400)\n",
    "\n",
    "result = results[0]\n",
    "len(result.boxes)\n",
    "result.boxes\n",
    "for box in result.boxes:\n",
    "    label = result.names[box.cls[0].item()]\n",
    "    cords = [round(x) for x in box.xyxy[0].tolist()]\n",
    "    prob = box.conf[0].item()\n",
    "    print(\"Object type: \", label)\n",
    "    print(\"Coordinates: \", cords)\n",
    "    print(\"Probability: \", prob)\n",
    "    print(\"---\")\n",
    "\n",
    "\n",
    "Image.fromarray(result.plot()[:,:,::-1])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# VIDEO CAPTURE "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "from roboflow import Roboflow\n",
    "from ultralytics import YOLO\n",
    " \n",
    "prev_frame_time = 0\n",
    "\n",
    "def fps():\n",
    "    global prev_frame_time\n",
    "    new_frame_time = time.time()\n",
    "    fps =1/(new_frame_time-prev_frame_time)\n",
    "    prev_frame_time = new_frame_time\n",
    "    fps = str(int(fps))\n",
    "\n",
    "    return fps\n",
    "\n",
    "cap = cv2.VideoCapture(0, cv2.CAP_DSHOW)\n",
    "cap.set(cv2.CAP_PROP_FOURCC, cv2.VideoWriter_fourcc(*\"MJPG\"))\n",
    "\n",
    "print(\"Frame default resolution: (\" + str(cap.get(cv2.CAP_PROP_FRAME_WIDTH)) + \"; \" + str(cap.get(cv2.CAP_PROP_FRAME_HEIGHT)) + \")\")\n",
    "\n",
    "\n",
    "if (cap.isOpened()== False): \n",
    "  print(\"Error opening video stream or file\")\n",
    " \n",
    "# Read until video is completed\n",
    "\n",
    "frames = 0\n",
    "total_time = 0\n",
    "\n",
    "while(True):\n",
    "  # Capture frame-by-frame\n",
    "  start_time = time.time()\n",
    "  frames+=1\n",
    "  \n",
    "  ret, frame = cap.read()\n",
    "  frame= cv2.resize(frame, (100,100))\n",
    "\n",
    "\n",
    "  if total_time>= 10:\n",
    "    fps1 = (frames)/total_time\n",
    "    cv2.putText(frame, fps1, (7, 70), cv2.FONT_HERSHEY_SIMPLEX, 1, (100, 255, 0), 1)\n",
    "\n",
    "  if ret == True:\n",
    "      \n",
    "    \n",
    "\n",
    "    cv2.imshow('Frame',frame)\n",
    "\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "      break\n",
    " \n",
    "  # Break the loop\n",
    "  else: \n",
    "    break\n",
    "  end_time = time.time()\n",
    "  diff = end_time-start_time\n",
    "  print(diff)\n",
    " \n",
    "# When everything done, release the video capture object\n",
    "cap.release()\n",
    " \n",
    "# Closes all the frames\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# VIDEO DETECTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TRACKING WITH YOLO TRACK\n",
    "\n",
    "model = YOLO('handle_cover_nano_400.pt')\n",
    "\n",
    "results = model.track(source = \"DPMVideo 2024-8-14 9-34-0.mp4\", show=True, imgsz = 640, tracker =\"bytetrack.yaml\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cap = cv2.VideoCapture(\"IMG_0066.mov\")\n",
    "\n",
    "while True:\n",
    "    success, frame = cap.read()\n",
    "    frame = cv2.resize(frame, (640, 640)) \n",
    "    w = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "    h = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "    print(\"w %f, h %f\" % (w,h))\n",
    "    print(\"width %f, height %f\" % (width, height))\n",
    "\n",
    "    time.sleep(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TRACKING WITH OPENCV from a video\n",
    "conf_arr = []\n",
    "\n",
    "def put_boxes(box, frame):\n",
    "    global conf_arr\n",
    "    # bounding box\n",
    "    confidence = math.ceil(box.conf[0]*100)/100\n",
    "    conf_arr.append(confidence)\n",
    "    if confidence >=0.6:\n",
    "        x1, y1, x2, y2 = box.xyxy[0]\n",
    "        x1, y1, x2, y2 = int(x1), int(y1), int(x2), int(y2) # convert to int values\n",
    "        #put box in cam\n",
    "        cv2.rectangle(frame, (x1, y1), (x2, y2), (0, 255, 0), 1)\n",
    "\n",
    "        #put text in cam\n",
    "        org = [x1, y1-5]\n",
    "        font = cv2.FONT_HERSHEY_SIMPLEX\n",
    "        fontScale = 0.5\n",
    "        color = (0, 255, 0)\n",
    "        thickness = 1\n",
    "        cv2.putText(frame, (\"%.2f\") % confidence, org, font, fontScale, color, thickness)\n",
    "    else:\n",
    "        pass\n",
    "\n",
    "classNames = [\"handle\"]\n",
    "\n",
    "#model = YOLO('handle_cover_nano_400.pt')\n",
    "openvino_model = YOLO(\"handle_cover_nano_400_v3_133_openvino_model/\")\n",
    "\n",
    "cap = cv2.VideoCapture(\"DPMVideo 2024-8-23 15-9-50.mp4\")\n",
    "\n",
    "while True:\n",
    "    success, frame = cap.read()\n",
    "    \n",
    "    results = openvino_model(frame, imgsz=640, iou = 0.1)\n",
    "    #results = model(frame, stream=True, imgsz = 640, iou = 0.1)\n",
    "    window_name = 'image'\n",
    "\n",
    "    # coordinates\n",
    "    for r in results:\n",
    "        boxes = r.boxes\n",
    "        handle_count = 0\n",
    "        cover_count = 0\n",
    "\n",
    "        for box in boxes:\n",
    "            # bounding box\n",
    "            label = r.names[box.cls[0].item()] \n",
    "\n",
    "            if label == \"handle\":\n",
    "                handle_count +=1\n",
    "            elif label == \"cover\":\n",
    "                cover_count +=1      \n",
    "            print(\"%d %d\" % (handle_count, cover_count))\n",
    "\n",
    "            confidence = math.ceil((box.conf[0]*100))/100\n",
    "            if confidence >= 0.6:\n",
    "                put_boxes(box, frame)\n",
    "\n",
    "    frame = cv2.resize(frame, (1728,972))\n",
    "    cv2.imshow(window_name, frame)\n",
    "    if cv2.waitKey(1) == ord('q'):\n",
    "        break\n",
    "\n",
    "\n",
    "sum = 0\n",
    "for i in range(len(conf_arr)):\n",
    "    sum += conf_arr[i]\n",
    "\n",
    "if len(conf_arr)!=0:\n",
    "    average_conf = sum/(len(conf_arr))\n",
    "else:\n",
    "    average_conf = 0\n",
    "print(average_conf)\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conf_arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(average_conf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TRACKING WITH OPENCV from webcam\n",
    "\n",
    "classNames = [\"handle\"]\n",
    "\n",
    "model = YOLO('handle_cover_small.pt')\n",
    "\n",
    "cap = cv2.VideoCapture(0, cv2.CAP_DSHOW)\n",
    "cap.set(cv2.CAP_PROP_FOURCC, cv2.VideoWriter_fourcc(*\"MJPG\"))\n",
    "\n",
    "while True:\n",
    "    start = time.time()\n",
    "    success, frame = cap.read()\n",
    "    results = model(frame, stream=True, imgsz = 640, iou = 0.1)\n",
    "    window_name = 'Webcam'\n",
    "\n",
    "    for r in results:\n",
    "        boxes = r.boxes\n",
    "\n",
    "        for box in boxes:\n",
    "\n",
    "            # bounding box\n",
    "            confidence = math.ceil((box.conf[0]*100))/100\n",
    "            cls = int(box.cls[0])\n",
    "            if confidence >=0.6:\n",
    "                x1, y1, x2, y2 = box.xyxy[0]\n",
    "                x1, y1, x2, y2 = int(x1), int(y1), int(x2), int(y2) # convert to int values\n",
    "                #put box in cam\n",
    "                cv2.rectangle(frame, (x1, y1), (x2, y2), (0, 255, 0), 1)\n",
    "\n",
    "                #put text in cam\n",
    "                org = [x1, y1-5]\n",
    "                org2 = [x2, y2-5]\n",
    "                font = cv2.FONT_HERSHEY_SIMPLEX\n",
    "                fontScale = 0.5\n",
    "                color = (0, 255, 0)\n",
    "                thickness = 1\n",
    "                cv2.putText(frame, (\"%.2f\") % confidence, org, font, fontScale, color, thickness)\n",
    "            else:\n",
    "                pass\n",
    "\n",
    "    frame = cv2.resize(frame, (100,100))\n",
    "    cv2.imshow(window_name, frame)\n",
    "    if cv2.waitKey(1) == ord('q'):\n",
    "        break\n",
    "    end = time.time()\n",
    "    print(end-start)\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = YOLO('handle_cover_nano_400_v3_133.pt')\n",
    "model.export(format = 'openvino', imgsz = 640)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TRACKING WITH OPENCV from webcam with OpenVINO\n",
    "\n",
    "classNames = [\"handle\"]\n",
    "\n",
    "model = YOLO('handle_cover_m2.pt')\n",
    "#model.export(format = 'openvino')\n",
    "openvino_model = YOLO(\"handle_cover_m_test_openvino_model/\")\n",
    "\n",
    "cap = cv2.VideoCapture(0, cv2.CAP_DSHOW)\n",
    "cap.set(cv2.CAP_PROP_FOURCC, cv2.VideoWriter_fourcc(*\"MJPG\"))\n",
    "\n",
    "while True:\n",
    "\n",
    "    success, frame = cap.read()\n",
    "    frame = cv2.resize(frame, (640, 640),)\n",
    "    #results=model(frame, imgsz=640, iou = 0.1)\n",
    "    results = openvino_model(frame, imgsz=640)\n",
    "    window_name = 'Webcam'\n",
    "\n",
    "    for r in results:\n",
    "        boxes = r.boxes\n",
    "\n",
    "        for box in boxes:\n",
    "\n",
    "            # bounding box\n",
    "            confidence = math.ceil((box.conf[0]*100))/100\n",
    "            cls = int(box.cls[0])\n",
    "            print(cls)\n",
    "            if confidence >=0.6:\n",
    "                x1, y1, x2, y2 = box.xyxy[0]\n",
    "                x1, y1, x2, y2 = int(x1), int(y1), int(x2), int(y2) # convert to int values\n",
    "                #put box in cam\n",
    "                cv2.rectangle(frame, (x1, y1), (x2, y2), (0, 255, 0), 1)\n",
    "\n",
    "                #put text in cam\n",
    "                org = [x1, y1-5]\n",
    "                org2 = [x2, y2-5]\n",
    "                font = cv2.FONT_HERSHEY_SIMPLEX\n",
    "                fontScale = 0.5\n",
    "                color = (0, 255, 0)\n",
    "                thickness = 1\n",
    "                cv2.putText(frame, (\"%.2f\") % confidence, org, font, fontScale, color, thickness)\n",
    "            else:\n",
    "                pass\n",
    "\n",
    "    \n",
    "    cv2.imshow(window_name, frame)\n",
    "    if cv2.waitKey(1) == ord('q'):\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TRACKING WITH OPENCV from webcam PLC\n",
    "import cv2\n",
    "import numpy as np\n",
    "from roboflow import Roboflow\n",
    "from ultralytics import YOLO\n",
    "from PIL import Image\n",
    "import math\n",
    "import time\n",
    "import snap7\n",
    "\n",
    "classNames = [\"handle\"]\n",
    "\n",
    "model = YOLO('Handle.pt')\n",
    "\n",
    "cap = cv2.VideoCapture(1, cv2.CAP_DSHOW)\n",
    "cap.set(cv2.CAP_PROP_FRAME_WIDTH, 1920)\n",
    "cap.set(cv2.CAP_PROP_FRAME_HEIGHT, 1080)\n",
    "#cap.set(cv2.CAP_PROP_FPS, 60)\n",
    "cap.set(cv2.CAP_PROP_FOURCC, cv2.VideoWriter_fourcc(*\"MJPG\"))\n",
    "\n",
    "plc = snap7.client.Client()\n",
    "plc.connect('192.168.1.119', 0 , 1)\n",
    "bytes = plc.db_read(1,10,1)\n",
    "test_start = snap7.util.get_bool(bytes, 0, 0)\n",
    "\n",
    "\n",
    "while True:\n",
    "\n",
    "    success, frame = cap.read()\n",
    "    #frame = cv2.resize(frame, (640, 360))\n",
    "    results = model(frame, stream=True)\n",
    "    window_name = 'Webcam'\n",
    "\n",
    "    for r in results:\n",
    "        boxes = r.boxes\n",
    "\n",
    "        #region SNAP7\n",
    "        test_int = plc.db_read(1,8,2)\n",
    "        snap7.util.set_int(test_int, 0, len(boxes))\n",
    "        plc.db_write(1, 8, test_int)\n",
    "\n",
    "        if len(boxes) != 0:\n",
    "            test_bool = plc.db_read(1,6,1)\n",
    "            snap7.util.set_bool(test_bool, 0, 0, True)\n",
    "            plc.db_write(1, 6, test_bool)\n",
    "        elif len(boxes) == 0:\n",
    "            test_bool = plc.db_read(1,6,1)\n",
    "            snap7.util.set_bool(test_bool, 0, 0, False)\n",
    "            plc.db_write(1, 6, test_bool)    \n",
    "        #endregion\n",
    "\n",
    "        for box in boxes:\n",
    "\n",
    "            # bounding box\n",
    "            confidence = math.ceil(box.conf[0]*100)/100\n",
    "            if confidence >=0.6:\n",
    "                x1, y1, x2, y2 = box.xyxy[0]\n",
    "                x1, y1, x2, y2 = int(x1), int(y1), int(x2), int(y2) # convert to int values\n",
    "                #put box in cam\n",
    "                cv2.rectangle(frame, (x1, y1), (x2, y2), (0, 255, 0), 1)\n",
    "\n",
    "                #put text in cam\n",
    "                org = [x1, y1-5]\n",
    "                org2 = [x2, y2-5]\n",
    "                font = cv2.FONT_HERSHEY_SIMPLEX\n",
    "                fontScale = 0.5\n",
    "                color = (0, 255, 0)\n",
    "                thickness = 1\n",
    "                cv2.putText(frame, (\"%.2f\") % confidence, org, font, fontScale, color, thickness)\n",
    "            else:\n",
    "                pass\n",
    "\n",
    "\n",
    "    cv2.imshow(window_name, frame)\n",
    "    if cv2.waitKey(1) == ord('q'):\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2, math\n",
    "from roboflow import Roboflow\n",
    "from ultralytics import YOLO\n",
    "import snap7\n",
    "import os, sys\n",
    "import multiprocessing\n",
    "import time\n",
    "\n",
    "def resource_path(relative):\n",
    "\n",
    "    try:\n",
    "        base_path = sys._MEIPASS\n",
    "    except Exception:\n",
    "        base_path = os.path.abspath(\".\")\n",
    "    return os.path.join(base_path, relative)\n",
    "\n",
    "\n",
    "def put_boxes(box, frame):\n",
    "\n",
    "    # bounding box\n",
    "    confidence = math.ceil(box.conf[0]*100)/100\n",
    "    if confidence >=0.6:\n",
    "        x1, y1, x2, y2 = box.xyxy[0]\n",
    "        x1, y1, x2, y2 = int(x1), int(y1), int(x2), int(y2) # convert to int values\n",
    "        #put box in cam\n",
    "        cv2.rectangle(frame, (x1, y1), (x2, y2), (0, 255, 0), 1)\n",
    "\n",
    "        #put text in cam\n",
    "        org = [x1, y1-5]\n",
    "        font = cv2.FONT_HERSHEY_SIMPLEX\n",
    "        fontScale = 0.5\n",
    "        color = (0, 255, 0)\n",
    "        thickness = 1\n",
    "        cv2.putText(frame, (\"%.2f\") % confidence, org, font, fontScale, color, thickness)\n",
    "    else:\n",
    "        pass\n",
    "\n",
    "def get_video(source):\n",
    "    cap = cv2.VideoCapture(source, cv2.CAP_DSHOW)\n",
    "    cap.set(cv2.CAP_PROP_FOURCC, cv2.VideoWriter_fourcc(*\"MJPG\"))\n",
    "\n",
    "    return cap\n",
    "def main():\n",
    "    \n",
    "    cap = get_video(0)\n",
    "\n",
    "    pt = resource_path('handle_cover_small.pt')\n",
    "    model = YOLO(pt)\n",
    "    #pt2 =resource_path(\"handle_cover_m2_openvino_model/\")\n",
    "    #openvino_model = YOLO(pt2)\n",
    "    plc = snap7.client.Client()\n",
    "\n",
    "    while True:\n",
    "                \n",
    "        success, frame = cap.read()\n",
    "        if success == False:\n",
    "            cap.release()\n",
    "            cap = get_video(0)\n",
    "            success, frame = cap.read()\n",
    "        else:\n",
    "            pass\n",
    "                        \n",
    "        if not plc.get_connected():\n",
    "            try:\n",
    "                plc.connect('192.168.1.19', 0 , 1)\n",
    "            except:\n",
    "                time.sleep(2)\n",
    "                pass           \n",
    "\n",
    "        elif plc.get_connected():\n",
    "            test_start_bytes = plc.db_read(20,2,1)\n",
    "            test_start = snap7.util.get_bool(test_start_bytes, 0, 0)\n",
    "\n",
    "            results = model(frame, stream=True, iou = 0.1)\n",
    "            #results = openvino_model(frame, imgsz = 640, iou = 0.1)\n",
    "            for r in results:\n",
    "                boxes = r.boxes\n",
    "                handle_count = 0\n",
    "                cover_count = 0\n",
    "                \n",
    "                for box in boxes:\n",
    "                    label = r.names[box.cls[0].item()] \n",
    "                    put_boxes(box, frame)\n",
    "                \n",
    "                    if label == \"handle\":\n",
    "                        handle_count +=1\n",
    "                    elif label == \"cover\":\n",
    "                        cover_count +=1      \n",
    "\n",
    "                if test_start:\n",
    "\n",
    "                    recete_bytes = plc.db_read(20,0,2)\n",
    "                    recete_no = snap7.util.get_int(recete_bytes, 0)   \n",
    "                    print(\"Recete: %d\" % recete_no)    \n",
    "\n",
    "                    if recete_no == 2 or recete_no == 8:       \n",
    "\n",
    "                        test_ok = plc.db_read(20,10,1)\n",
    "\n",
    "                        if handle_count == 2 and cover_count == 2:                   \n",
    "                            snap7.util.set_bool(test_ok, 0, 0, True)\n",
    "                            plc.db_write(20, 10, test_ok)\n",
    "                            print(\"TEST COMPLETED\")\n",
    "                        else:\n",
    "                            snap7.util.set_bool(test_ok, 0, 0, False)\n",
    "                            plc.db_write(20, 10, test_ok)    \n",
    "                            \n",
    "                    elif recete_no == 6:\n",
    "                        \n",
    "                        test_ok = plc.db_read(20,10,1)\n",
    "\n",
    "                        if cover_count == 2 and handle_count == 0:                    \n",
    "                            snap7.util.set_bool(test_ok, 0, 0, True)\n",
    "                            plc.db_write(20, 10, test_ok)\n",
    "                            print(\"TEST COMPLETED\")\n",
    "                        else:                    \n",
    "                            snap7.util.set_bool(test_ok, 0, 0, False)\n",
    "                            plc.db_write(20, 10, test_ok)        \n",
    "\n",
    "        frame = cv2.resize(frame, (640, 640))            \n",
    "        cv2.imshow(\"handle_cover_detection\", frame)\n",
    "        if cv2.waitKey(1) == ord('q'):\n",
    "            break\n",
    "\n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    multiprocessing.freeze_support()\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
